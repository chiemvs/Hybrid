{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sys.path.append(os.path.expanduser('~/Documents/Hybrid/'))\n",
    "from Hybrid.neuralnet import construct_modeldev_model, earlystop, BrierScore, ConstructorAndCompiler\n",
    "#from Hybrid.optimization import multi_fit_multi_eval, multi_fit_single_eval, ranked_prob_score\n",
    "from Hybrid.dataprep import test_trainval_split, multiclass_log_forecastprob, singleclass_regression, multiclass_logistic_regression_coefficients, scale_other_features\n",
    "from Hybrid.interpretation import combine_input_output, composite_extremes\n",
    "\n",
    "crossval = True # Only for the trainvalsplit.\n",
    "nfolds = 3\n",
    "balanced = True\n",
    "focus_class = -1 # Index of the class to be scored and benchmarked through bss\n",
    "\n",
    "name = 'tg-ex-q0.75-21D_ge7D_sep12-15'\n",
    "#name = 'tg-ex-q0.75-21D_ge7D_sep19-21'\n",
    "name2 = 'tg-anom_JJA_45r1_31D-roll-mean_sep12-15'\n",
    "\n",
    "#predictor_dir = Path('/nobackup/users/straaten/predsets/objective_balanced_cv/no_pdomjo/') # Can change to the objectively selected sets\n",
    "predictor_dir = Path('/nobackup/users/straaten/predsets/objective_balanced_cv/') # Can change to the objectively selected sets\n",
    "for_obs_dir = Path('/nobackup/users/straaten/predsets/full/') \n",
    "\n",
    "predictors = pd.read_hdf(predictor_dir / f'{name2}_multi_d15_b3_predictors.h5', key = 'input').iloc[:,:7]\n",
    "forc = pd.read_hdf(for_obs_dir / f'{name}_forc.h5', key = 'input')\n",
    "obs= pd.read_hdf(for_obs_dir / f'{name}_obs.h5', key = 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting a new feature scaler\n"
     ]
    }
   ],
   "source": [
    "# Preparing only the trainval set.\n",
    "X_test, X_trainval, generator = test_trainval_split(predictors, crossval = crossval, nfolds = nfolds, balanced = balanced)\n",
    "forc_test, forc_trainval, generator = test_trainval_split(forc, crossval = crossval, nfolds = nfolds, balanced = balanced)\n",
    "obs_test, obs_trainval, generator = test_trainval_split(obs, crossval = crossval, nfolds = nfolds, balanced = balanced)\n",
    "\n",
    "feature_input, feature_scaler = scale_other_features(X_trainval)\n",
    "raw_predictions = multiclass_log_forecastprob(forc_trainval)\n",
    "obs_input = obs_trainval.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th colspan=\"3\" halign=\"left\">sst_nhplus</th>\n",
       "      <th>siconc_nhmin</th>\n",
       "      <th>sst_nhplus</th>\n",
       "      <th>transp_europe</th>\n",
       "      <th>swvl13_europe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>timeagg</th>\n",
       "      <th>21</th>\n",
       "      <th>15</th>\n",
       "      <th>7</th>\n",
       "      <th>31</th>\n",
       "      <th>11</th>\n",
       "      <th>31</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>clustid</th>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>spatcov</th>\n",
       "      <th>spatcov</th>\n",
       "      <th>spatcov</th>\n",
       "      <th>spatcov</th>\n",
       "      <th>spatcov</th>\n",
       "      <th>spatcov</th>\n",
       "      <th>spatcov</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th>separation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998-06-19</th>\n",
       "      <th>12</th>\n",
       "      <td>-0.051529</td>\n",
       "      <td>0.030985</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>-0.056700</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.000439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-06-20</th>\n",
       "      <th>13</th>\n",
       "      <td>-0.050145</td>\n",
       "      <td>0.031957</td>\n",
       "      <td>-0.000919</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>-0.056194</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.000433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-06-21</th>\n",
       "      <th>14</th>\n",
       "      <td>-0.049024</td>\n",
       "      <td>0.032371</td>\n",
       "      <td>-0.000980</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>-0.056300</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-06-22</th>\n",
       "      <th>15</th>\n",
       "      <td>-0.048194</td>\n",
       "      <td>0.032323</td>\n",
       "      <td>-0.000972</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>-0.057027</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.000427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-06-23</th>\n",
       "      <th>12</th>\n",
       "      <td>-0.047589</td>\n",
       "      <td>0.031867</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>-0.058528</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>0.000419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-21</th>\n",
       "      <th>15</th>\n",
       "      <td>-0.009250</td>\n",
       "      <td>-0.022996</td>\n",
       "      <td>-0.000522</td>\n",
       "      <td>-0.005122</td>\n",
       "      <td>0.017135</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>-0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-22</th>\n",
       "      <th>12</th>\n",
       "      <td>-0.009223</td>\n",
       "      <td>-0.023906</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>-0.005416</td>\n",
       "      <td>0.017303</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>-0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-23</th>\n",
       "      <th>13</th>\n",
       "      <td>-0.009382</td>\n",
       "      <td>-0.024418</td>\n",
       "      <td>-0.000467</td>\n",
       "      <td>-0.005723</td>\n",
       "      <td>0.018011</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-24</th>\n",
       "      <th>14</th>\n",
       "      <td>-0.009428</td>\n",
       "      <td>-0.024719</td>\n",
       "      <td>-0.000381</td>\n",
       "      <td>-0.006028</td>\n",
       "      <td>0.019147</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.000205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-25</th>\n",
       "      <th>15</th>\n",
       "      <td>-0.009570</td>\n",
       "      <td>-0.025504</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>-0.006298</td>\n",
       "      <td>0.020860</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.000255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2272 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "variable              sst_nhplus                     siconc_nhmin sst_nhplus  \\\n",
       "timeagg                       21        15        7            31         11   \n",
       "clustid                        4         1         0            1          2   \n",
       "metric                   spatcov   spatcov   spatcov      spatcov    spatcov   \n",
       "time       separation                                                          \n",
       "1998-06-19 12          -0.051529  0.030985 -0.000787     0.002585  -0.056700   \n",
       "1998-06-20 13          -0.050145  0.031957 -0.000919     0.002649  -0.056194   \n",
       "1998-06-21 14          -0.049024  0.032371 -0.000980     0.002755  -0.056300   \n",
       "1998-06-22 15          -0.048194  0.032323 -0.000972     0.002891  -0.057027   \n",
       "1998-06-23 12          -0.047589  0.031867 -0.000904     0.003043  -0.058528   \n",
       "...                          ...       ...       ...          ...        ...   \n",
       "2019-06-21 15          -0.009250 -0.022996 -0.000522    -0.005122   0.017135   \n",
       "2019-06-22 12          -0.009223 -0.023906 -0.000518    -0.005416   0.017303   \n",
       "2019-06-23 13          -0.009382 -0.024418 -0.000467    -0.005723   0.018011   \n",
       "2019-06-24 14          -0.009428 -0.024719 -0.000381    -0.006028   0.019147   \n",
       "2019-06-25 15          -0.009570 -0.025504 -0.000348    -0.006298   0.020860   \n",
       "\n",
       "variable              transp_europe swvl13_europe  \n",
       "timeagg                          31            11  \n",
       "clustid                           1             0  \n",
       "metric                      spatcov       spatcov  \n",
       "time       separation                              \n",
       "1998-06-19 12             -0.000023      0.000439  \n",
       "1998-06-20 13             -0.000028      0.000433  \n",
       "1998-06-21 14             -0.000032      0.000428  \n",
       "1998-06-22 15             -0.000036      0.000427  \n",
       "1998-06-23 12             -0.000039      0.000419  \n",
       "...                             ...           ...  \n",
       "2019-06-21 15              0.000038     -0.000095  \n",
       "2019-06-22 12              0.000036     -0.000121  \n",
       "2019-06-23 13              0.000033     -0.000160  \n",
       "2019-06-24 14              0.000033     -0.000205  \n",
       "2019-06-25 15              0.000032     -0.000255  \n",
       "\n",
       "[2272 rows x 7 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the model\n",
    "construct_kwargs = dict(n_classes = obs_trainval.shape[-1],\n",
    "        n_hidden_layers= 1,\n",
    "        n_features = feature_input.shape[-1],\n",
    "        n_hiddenlayer_nodes = 4)\n",
    "\n",
    "compile_kwargs = dict(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics = ['accuracy',BrierScore(class_index = focus_class)])\n",
    "\n",
    "constructor = ConstructorAndCompiler(construct_modeldev_model, construct_kwargs, compile_kwargs)\n",
    "\n",
    "fit_kwargs = dict(batch_size = 32, epochs = 200, shuffle = True, callbacks = [earlystop(patience = 7, monitor = 'val_loss')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.7014 - brier: 0.1994 - val_loss: 0.6794 - val_accuracy: 0.6328 - val_brier: 0.2330\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5886 - accuracy: 0.7014 - brier: 0.1988 - val_loss: 0.6758 - val_accuracy: 0.6328 - val_brier: 0.2311\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5868 - accuracy: 0.7014 - brier: 0.1980 - val_loss: 0.6755 - val_accuracy: 0.6328 - val_brier: 0.2310\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5840 - accuracy: 0.7014 - brier: 0.1969 - val_loss: 0.6746 - val_accuracy: 0.6328 - val_brier: 0.2307\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5800 - accuracy: 0.7014 - brier: 0.1951 - val_loss: 0.6725 - val_accuracy: 0.6328 - val_brier: 0.2297\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5741 - accuracy: 0.7049 - brier: 0.1929 - val_loss: 0.6736 - val_accuracy: 0.6328 - val_brier: 0.2306\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.7153 - brier: 0.1902 - val_loss: 0.6714 - val_accuracy: 0.6328 - val_brier: 0.2296\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5599 - accuracy: 0.7170 - brier: 0.1871 - val_loss: 0.6720 - val_accuracy: 0.6432 - val_brier: 0.2302\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5519 - accuracy: 0.7196 - brier: 0.1838 - val_loss: 0.6661 - val_accuracy: 0.6432 - val_brier: 0.2274\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7283 - brier: 0.1807 - val_loss: 0.6676 - val_accuracy: 0.6419 - val_brier: 0.2285\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5367 - accuracy: 0.7439 - brier: 0.1777 - val_loss: 0.6660 - val_accuracy: 0.6354 - val_brier: 0.2280\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5304 - accuracy: 0.7465 - brier: 0.1751 - val_loss: 0.6610 - val_accuracy: 0.6458 - val_brier: 0.2256\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5228 - accuracy: 0.7517 - brier: 0.1720 - val_loss: 0.6571 - val_accuracy: 0.6510 - val_brier: 0.2239\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.7561 - brier: 0.1697 - val_loss: 0.6504 - val_accuracy: 0.6797 - val_brier: 0.2205\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7578 - brier: 0.1670 - val_loss: 0.6499 - val_accuracy: 0.6732 - val_brier: 0.2205\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.7561 - brier: 0.1648 - val_loss: 0.6502 - val_accuracy: 0.6706 - val_brier: 0.2210\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7587 - brier: 0.1626 - val_loss: 0.6464 - val_accuracy: 0.6823 - val_brier: 0.2192\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7665 - brier: 0.1607 - val_loss: 0.6474 - val_accuracy: 0.6758 - val_brier: 0.2200\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.7674 - brier: 0.1588 - val_loss: 0.6409 - val_accuracy: 0.6901 - val_brier: 0.2167\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7656 - brier: 0.1571 - val_loss: 0.6378 - val_accuracy: 0.6927 - val_brier: 0.2153\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7674 - brier: 0.1555 - val_loss: 0.6395 - val_accuracy: 0.6836 - val_brier: 0.2165\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7726 - brier: 0.1540 - val_loss: 0.6342 - val_accuracy: 0.6966 - val_brier: 0.2138\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7717 - brier: 0.1523 - val_loss: 0.6339 - val_accuracy: 0.6953 - val_brier: 0.2139\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7752 - brier: 0.1512 - val_loss: 0.6297 - val_accuracy: 0.6979 - val_brier: 0.2117\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7821 - brier: 0.1498 - val_loss: 0.6307 - val_accuracy: 0.6940 - val_brier: 0.2125\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7847 - brier: 0.1494 - val_loss: 0.6264 - val_accuracy: 0.6979 - val_brier: 0.2103\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7882 - brier: 0.1479 - val_loss: 0.6313 - val_accuracy: 0.6953 - val_brier: 0.2132\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7934 - brier: 0.1471 - val_loss: 0.6291 - val_accuracy: 0.6953 - val_brier: 0.2122\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.7899 - brier: 0.1457 - val_loss: 0.6248 - val_accuracy: 0.6953 - val_brier: 0.2099\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7951 - brier: 0.1450 - val_loss: 0.6200 - val_accuracy: 0.7005 - val_brier: 0.2074\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.7943 - brier: 0.1441 - val_loss: 0.6227 - val_accuracy: 0.6966 - val_brier: 0.2091\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7986 - brier: 0.1431 - val_loss: 0.6233 - val_accuracy: 0.6966 - val_brier: 0.2095\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.8012 - brier: 0.1423 - val_loss: 0.6160 - val_accuracy: 0.7018 - val_brier: 0.2055\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.8021 - brier: 0.1414 - val_loss: 0.6214 - val_accuracy: 0.6966 - val_brier: 0.2087\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.8003 - brier: 0.1410 - val_loss: 0.6155 - val_accuracy: 0.7018 - val_brier: 0.2055\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.8021 - brier: 0.1401 - val_loss: 0.6208 - val_accuracy: 0.7031 - val_brier: 0.2085\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.8056 - brier: 0.1396 - val_loss: 0.6204 - val_accuracy: 0.7031 - val_brier: 0.2084\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.8073 - brier: 0.1394 - val_loss: 0.6136 - val_accuracy: 0.7044 - val_brier: 0.2046\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.8056 - brier: 0.1385 - val_loss: 0.6126 - val_accuracy: 0.7057 - val_brier: 0.2041\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.8073 - brier: 0.1382 - val_loss: 0.6218 - val_accuracy: 0.7005 - val_brier: 0.2093\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.8056 - brier: 0.1374 - val_loss: 0.6155 - val_accuracy: 0.7057 - val_brier: 0.2059\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.8116 - brier: 0.1369 - val_loss: 0.6104 - val_accuracy: 0.7109 - val_brier: 0.2029\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.8108 - brier: 0.1366 - val_loss: 0.6142 - val_accuracy: 0.7057 - val_brier: 0.2052\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8090 - brier: 0.1358 - val_loss: 0.6099 - val_accuracy: 0.7135 - val_brier: 0.2026\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8142 - brier: 0.1356 - val_loss: 0.6162 - val_accuracy: 0.7005 - val_brier: 0.2064\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.8125 - brier: 0.1352 - val_loss: 0.6136 - val_accuracy: 0.7031 - val_brier: 0.2049\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.8177 - brier: 0.1348 - val_loss: 0.6126 - val_accuracy: 0.7044 - val_brier: 0.2043\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.8194 - brier: 0.1344 - val_loss: 0.6057 - val_accuracy: 0.7135 - val_brier: 0.2001\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.8177 - brier: 0.1344 - val_loss: 0.6117 - val_accuracy: 0.7044 - val_brier: 0.2038\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.8125 - brier: 0.1338 - val_loss: 0.6113 - val_accuracy: 0.7057 - val_brier: 0.2035\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.8142 - brier: 0.1332 - val_loss: 0.6125 - val_accuracy: 0.6979 - val_brier: 0.2043\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.8194 - brier: 0.1333 - val_loss: 0.6134 - val_accuracy: 0.6979 - val_brier: 0.2047\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.8186 - brier: 0.1329 - val_loss: 0.6154 - val_accuracy: 0.6966 - val_brier: 0.2058\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.8220 - brier: 0.1329 - val_loss: 0.6123 - val_accuracy: 0.7031 - val_brier: 0.2040\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.8220 - brier: 0.1323 - val_loss: 0.6060 - val_accuracy: 0.7135 - val_brier: 0.2001\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00055: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd1b43a87f0>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model = constructor.fresh_model()\n",
    "model.fit(x = [feature_input, raw_predictions], y=obs_input, validation_split = 0.4, **fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using a pre-fitted feature scaler\n"
     ]
    }
   ],
   "source": [
    "# Test the predictions\n",
    "test_features, _ = scale_other_features(X_test, fitted_scaler=feature_scaler)\n",
    "test_forcs = multiclass_log_forecastprob(forc_test)\n",
    "test_preds = model.predict(x = [test_features, test_forcs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 638us/step - loss: 0.6052 - accuracy: 0.7074 - brier: 0.2008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6051961183547974, 0.7073863744735718, 0.2008126676082611]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x = [test_features, test_forcs], y = obs_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23460872275046382"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((obs_test.iloc[:,focus_class] - forc_test.iloc[:,focus_class])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.202847"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((obs_test.iloc[:,focus_class] - test_preds[:,focus_class])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLVENV",
   "language": "python",
   "name": "dlvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
